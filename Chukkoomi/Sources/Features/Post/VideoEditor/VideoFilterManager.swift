//
//  VideoFilterManager.swift
//  Chukkoomi
//
//  Created by ê¹€ì˜í›ˆ on 11/15/25.
//

import UIKit
import AVFoundation
@preconcurrency import CoreImage
import Vision
import CoreML
import Metal

/// ë¹„ë””ì˜¤ í•„í„° íƒ€ì…
enum VideoFilter: String, CaseIterable, Equatable {
    case blackAndWhite = "í‘ë°±"
    case warm = "ë”°ëœ»í•œ"
    case cool = "ì°¨ê°‘ê²Œ"
    case animeGANHayao = "ê·¸ë¦¼"

    var displayName: String {
        return rawValue
    }
}

/// ë¹„ë””ì˜¤ í•„í„° ê´€ë¦¬ì
struct VideoFilterManager {

    /// ë¹„ë””ì˜¤ì— í•„í„°ë¥¼ ì ìš©í•œ AVVideoComposition ìƒì„±
    /// - Parameters:
    ///   - asset: ì›ë³¸ ë¹„ë””ì˜¤ AVAsset
    ///   - filter: ì ìš©í•  í•„í„°
    ///   - targetSize: ëª©í‘œ í¬ê¸° (nilì´ë©´ ì›ë³¸ í¬ê¸° ì‚¬ìš©)
    /// - Returns: í•„í„°ê°€ ì ìš©ëœ AVVideoComposition (í•„í„°ê°€ ì—†ìœ¼ë©´ nil)
    static func createVideoComposition(
        for asset: AVAsset,
        filter: VideoFilter?,
        targetSize: CGSize? = nil,
        isPortraitFromPHAsset: Bool
    ) async -> AVVideoComposition? {
        // í•„í„°ê°€ ì—†ìœ¼ë©´ nil ë°˜í™˜
        guard let filter = filter else {
            return nil
        }

        // ë¹„ë””ì˜¤ íŠ¸ë™ ê°€ì ¸ì˜¤ê¸°
        guard let videoTrack = try? await asset.loadTracks(withMediaType: .video).first else {
            return nil
        }

        let naturalSize = try? await videoTrack.load(.naturalSize)
        let preferredTransform = try? await videoTrack.load(.preferredTransform)

        guard let naturalSize = naturalSize else {
            return nil
        }

        // ë””ë²„ê¹… ë¡œê·¸
        print("ğŸ¬ [VideoFilterManager] ====== í•„í„° ì ìš© ì‹œì‘ ======")
        print("ğŸ¬ [VideoFilterManager] ì›ë³¸ naturalSize: \(naturalSize)")
        print("ğŸ¬ [VideoFilterManager] isPortraitFromPHAsset: \(isPortraitFromPHAsset)")
        print("ğŸ¬ [VideoFilterManager] targetSize íŒŒë¼ë¯¸í„°: \(targetSize ?? .zero)")

        // naturalSizeê°€ ê°€ë¡œ ë°©í–¥ì¸ì§€ í™•ì¸
        let isNaturalSizePortrait = naturalSize.width < naturalSize.height
        print("ğŸ¬ [VideoFilterManager] isNaturalSizePortrait: \(isNaturalSizePortrait)")

        // ì„¸ë¡œ ì˜ìƒì¸ë° naturalSizeê°€ ê°€ë¡œë¡œ ë‚˜ì˜¨ ê²½ìš° swap
        let adjustedNaturalSize: CGSize
        if isPortraitFromPHAsset && !isNaturalSizePortrait {
            adjustedNaturalSize = CGSize(width: naturalSize.height, height: naturalSize.width)
            print("ğŸ¬ [VideoFilterManager] naturalSize swap: \(adjustedNaturalSize)")
        } else {
            adjustedNaturalSize = naturalSize
            print("ğŸ¬ [VideoFilterManager] naturalSize ìœ ì§€: \(adjustedNaturalSize)")
        }

        // renderSize ê³„ì‚°
        let renderSize = targetSize ?? adjustedNaturalSize
        print("ğŸ¬ [VideoFilterManager] renderSize: \(renderSize)")

        // ì„¸ë¡œ ì˜ìƒì¸ë° naturalSizeê°€ ê°€ë¡œì˜€ìœ¼ë©´ 90ë„ íšŒì „ í•„ìš”
        let correctedTransform: CGAffineTransform
        if isPortraitFromPHAsset && !isNaturalSizePortrait {
            correctedTransform = CGAffineTransform(a: 0, b: 1, c: -1, d: 0, tx: 0, ty: 0)
            print("ğŸ¬ [VideoFilterManager] âœ… ì„¸ë¡œ ì˜ìƒ - 90ë„ íšŒì „ transform ì ìš©")
        } else {
            correctedTransform = preferredTransform ?? .identity
            print("ğŸ¬ [VideoFilterManager] ì›ë³¸ transform ì‚¬ìš©")
        }
        print("ğŸ¬ [VideoFilterManager] ====== í•„í„° ì ìš© ì¢…ë£Œ ======")


        // aspect-fit ìŠ¤ì¼€ì¼ ê³„ì‚°
        let scaleX = renderSize.width / adjustedNaturalSize.width
        let scaleY = renderSize.height / adjustedNaturalSize.height
        let scale = min(scaleX, scaleY)
        print("ğŸ¬ [VideoFilterManager] scale: \(scale) (scaleX: \(scaleX), scaleY: \(scaleY))")

        // ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ offset ê³„ì‚° (ì›ë³¸ naturalSize ê¸°ì¤€)
        let scaledWidth = naturalSize.width * scale
        let scaledHeight = naturalSize.height * scale
        print("ğŸ¬ [VideoFilterManager] scaledWidth: \(scaledWidth), scaledHeight: \(scaledHeight)")

        let offsetX: CGFloat
        let offsetY: CGFloat

        if isPortraitFromPHAsset && !isNaturalSizePortrait {
            // ì„¸ë¡œ ì˜ìƒì´ê³  íšŒì „ í•„ìš”í•œ ê²½ìš°: 90ë„ íšŒì „ í›„ ì¤‘ì•™ ì •ë ¬
            offsetX = (renderSize.width - scaledHeight) / 2
            offsetY = (renderSize.height - scaledWidth) / 2
        } else {
            // ê°€ë¡œ ì˜ìƒ ë˜ëŠ” íšŒì „ ë¶ˆí•„ìš”: ì¼ë°˜ ì¤‘ì•™ ì •ë ¬
            offsetX = (renderSize.width - scaledWidth) / 2
            offsetY = (renderSize.height - scaledHeight) / 2
        }
        print("ğŸ¬ [VideoFilterManager] offset: (\(offsetX), \(offsetY))")

        // AVVideoComposition ìƒì„± (í•„í„° + ë¦¬ì‚¬ì´ì¦ˆë¥¼ CIImageë¡œ ì²˜ë¦¬)
        let composition = AVMutableVideoComposition(
            asset: asset,
            applyingCIFiltersWithHandler: { request in
                let source = request.sourceImage

                // í•„í„° ì ìš©
                let filtered = applyFilter(filter, to: source, originalImage: source, targetSize: nil)

                // aspect-fit ë¦¬ì‚¬ì´ì§• ë° íšŒì „
                let scaleTransform = CGAffineTransform(scaleX: scale, y: scale)
                // íšŒì „ ì ìš© (ì„¸ë¡œ ì˜ìƒì¸ ê²½ìš°)
                let transformWithRotation = scaleTransform.concatenating(correctedTransform)

                // ì¤‘ì•™ ì •ë ¬
                let translateTransform = CGAffineTransform(translationX: offsetX, y: offsetY)
                let finalTransform = transformWithRotation.concatenating(translateTransform)

                let transformed = filtered.transformed(by: finalTransform)

                // renderSize ì˜ì—­ìœ¼ë¡œ crop
                let output = transformed.cropped(to: CGRect(origin: .zero, size: renderSize))

                // GPU ê°€ì† ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
                request.finish(with: output, context: VideoFilterHelper.gpuContext)
            }
        )

        composition.renderSize = renderSize

        return composition
    }

    // MARK: - Private Helper Methods

    /// CIImageì— í•„í„° ì ìš© (VideoFilterHelper ì‚¬ìš©)
    private static func applyFilter(_ filter: VideoFilter, to image: CIImage, originalImage: CIImage, targetSize: CGSize? = nil) -> CIImage {
        return VideoFilterHelper.applyFilter(filter, to: image, originalImage: originalImage, targetSize: targetSize)
    }

    /// ë¹„ë””ì˜¤ orientation í™•ì¸ í—¬í¼
    private static func orientation(from transform: CGAffineTransform) -> (orientation: UIImage.Orientation, isPortrait: Bool) {
        var assetOrientation = UIImage.Orientation.up
        var isPortrait = false

        if transform.a == 0 && transform.b == 1.0 && transform.c == -1.0 && transform.d == 0 {
            assetOrientation = .right
            isPortrait = true
        } else if transform.a == 0 && transform.b == -1.0 && transform.c == 1.0 && transform.d == 0 {
            assetOrientation = .left
            isPortrait = true
        } else if transform.a == 1.0 && transform.b == 0 && transform.c == 0 && transform.d == 1.0 {
            assetOrientation = .up
        } else if transform.a == -1.0 && transform.b == 0 && transform.c == 0 && transform.d == -1.0 {
            assetOrientation = .down
        }

        return (assetOrientation, isPortrait)
    }
}
